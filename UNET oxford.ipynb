{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, \\\n",
    "    Dropout, Conv2DTranspose, Cropping2D, Add\n",
    "#from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = CrfRnnLayer(image_dims=(height, width),\n",
    "                         num_classes=21,\n",
    "                         theta_alpha=160.,\n",
    "                         theta_beta=3.,\n",
    "                         theta_gamma=3.,\n",
    "                         num_iterations=10,\n",
    "                         name='crfrnn')([upscore, img_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crfrnn_model_def():\n",
    "    \"\"\" Returns Keras CRN-RNN model definition.\n",
    "\n",
    "    Currently, only 500 x 500 images are supported. However, one can get this to\n",
    "    work with different image sizes by adjusting the parameters of the Cropping2D layers\n",
    "    below.\n",
    "    \"\"\"\n",
    "\n",
    "    channels, height, width = 1, 512, 512 #Here the channel is 3 (RGB), but for us we will have only 1 channel\n",
    "\n",
    "    # Input\n",
    "    input_shape = (height, width, 3)\n",
    "    img_input = Input(shape=input_shape)  #They made an explicit input layer\n",
    "\n",
    "    # Add plenty of zero padding\n",
    "    x = ZeroPadding2D(padding=(100, 100))(img_input) #In order for a layer to have the same height and width as the previous layer, we pad with zeros. (Border it)\n",
    "\n",
    "    # VGG-16 convolution block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='valid', name='conv1_1')(x) #assuming filters=64, strides\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # VGG-16 convolution block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2', padding='same')(x)\n",
    "\n",
    "    # VGG-16 convolution block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3', padding='same')(x)\n",
    "    pool3 = x\n",
    "\n",
    "    # VGG-16 convolution block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4', padding='same')(x)\n",
    "    pool4 = x\n",
    "\n",
    "    # VGG-16 convolution block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5', padding='same')(x)\n",
    "\n",
    "    # Fully-connected layers converted to convolution layers\n",
    "    x = Conv2D(4096, (7, 7), activation='relu', padding='valid', name='fc6')(x) #with valid padding there is no zero padding and the neuron's receptive field lies strictly in \n",
    "    #valid positions of the input\n",
    "    x = Dropout(0.5)(x) #The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "    #Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference.\n",
    "    x = Conv2D(4096, (1, 1), activation='relu', padding='valid', name='fc7')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(21, (1, 1), padding='valid', name='score-fr')(x)\n",
    "\n",
    "    # Deconvolution\n",
    "    score2 = Conv2DTranspose(21, (4, 4), strides=2, name='score2')(x) #upscaling while conv2d is downscaling\n",
    "\n",
    "    # Skip connections from pool4\n",
    "    score_pool4 = Conv2D(21, (1, 1), name='score-pool4')(pool4)\n",
    "    score_pool4c = Cropping2D((5, 5))(score_pool4)\n",
    "    score_fused = Add()([score2, score_pool4c])\n",
    "    score4 = Conv2DTranspose(21, (4, 4), strides=2, name='score4', use_bias=False)(score_fused)\n",
    "\n",
    "    # Skip connections from pool3\n",
    "    score_pool3 = Conv2D(21, (1, 1), name='score-pool3')(pool3)\n",
    "    score_pool3c = Cropping2D((9, 9))(score_pool3)\n",
    "\n",
    "    # Fuse things together\n",
    "    score_final = Add()([score4, score_pool3c])\n",
    "\n",
    "    # Final up-sampling and cropping\n",
    "    upsample = Conv2DTranspose(21, (16, 16), strides=8, name='upsample', use_bias=False)(score_final)\n",
    "    upscore = Cropping2D(((31, 37), (31, 37)))(upsample)\n",
    "\n",
    "    \n",
    "\n",
    "    # Build the model\n",
    "    model = Model(img_input, upscore, name='crfrnn_net')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (36, 36, 21) (35, 35, 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ad05abbb96b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_crfrnn_model_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-378f04c7f339>\u001b[0m in \u001b[0;36mget_crfrnn_model_def\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mscore_pool4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'score-pool4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mscore_pool4c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCropping2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_pool4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mscore_fused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_pool4c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mscore4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'score4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             output_shape = self._compute_elemwise_op_output_shape(output_shape,\n\u001b[0;32m---> 91\u001b[0;31m                                                                   shape)\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     raise ValueError('Operands could not be broadcast '\n\u001b[1;32m     60\u001b[0m                                      \u001b[0;34m'together with shapes '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                      str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (36, 36, 21) (35, 35, 21)"
     ]
    }
   ],
   "source": [
    "model=get_crfrnn_model_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
